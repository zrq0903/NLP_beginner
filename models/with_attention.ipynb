{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:08:20.877289Z",
     "start_time": "2024-11-23T11:08:20.846010Z"
    }
   },
   "source": [
    "# Importing the libraries\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import embedding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.negative_sampling import vocab"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:08:20.892910Z",
     "start_time": "2024-11-23T11:08:20.877289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_input_len = 46\n",
    "max_output_len = 46\n",
    "sos_token = 0\n",
    "eos_token = 1\n",
    "pad_token = 2\n",
    "batch_size = 16"
   ],
   "id": "f15106d1f3a2dcd",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:08:20.932314Z",
     "start_time": "2024-11-23T11:08:20.916691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r\"..\\dataset\\ELRC-417-Swedish_Work_Environ.en-fr.en\", 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "src_sentences = []\n",
    "#print(len(lines))\n",
    "for line in lines[1:-1]:\n",
    "    src_sentences.append(line.lower().strip())\n",
    "\n",
    "with open(r\"..\\dataset\\ELRC-417-Swedish_Work_Environ.en-fr.fr\", 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "trg_sentences = []\n",
    "for line in lines[1:-1]:\n",
    "    trg_sentences.append(line.lower().strip())"
   ],
   "id": "b513fb6c0c5c622e",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:08:20.994798Z",
     "start_time": "2024-11-23T11:08:20.963556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.word_tokenize(src_sentences[0])\n",
    "max(len(nltk.word_tokenize(sentence)) for sentence in trg_sentences)"
   ],
   "id": "274bd48f562452b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:08:21.041664Z",
     "start_time": "2024-11-23T11:08:21.026043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "src_word_list = []\n",
    "for sentence in src_sentences:\n",
    "    src_word_list.extend([word.lower() for word in sentence[:-1].split()])\n",
    "#len(src_word_list)\n",
    "src_vocab = set(src_word_list)\n",
    "\n",
    "src_vocab = list(src_vocab)\n",
    "src_vocab.extend(['<unk>','<pad>','<sos>','<eos>','.',','])\n",
    "trg_word_list = []\n",
    "for sentence in trg_sentences:\n",
    "    trg_word_list.extend([word.lower() for word in sentence[:-1].split()])\n",
    "trg_vocab = list(set(trg_word_list))\n",
    "trg_vocab.extend(['<unk>','<pad>','<sos>','<eos>','.',','])\n",
    "trg_vocab\n",
    "'''"
   ],
   "id": "8181c86554511dfb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsrc_word_list = []\\nfor sentence in src_sentences:\\n    src_word_list.extend([word.lower() for word in sentence[:-1].split()])\\n#len(src_word_list)\\nsrc_vocab = set(src_word_list)\\n\\nsrc_vocab = list(src_vocab)\\nsrc_vocab.extend(['<unk>','<pad>','<sos>','<eos>','.',','])\\ntrg_word_list = []\\nfor sentence in trg_sentences:\\n    trg_word_list.extend([word.lower() for word in sentence[:-1].split()])\\ntrg_vocab = list(set(trg_word_list))\\ntrg_vocab.extend(['<unk>','<pad>','<sos>','<eos>','.',','])\\ntrg_vocab\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "maybe try nltk.tokenize tomorrow",
   "id": "e1e2433d30df8280"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:08:21.104147Z",
     "start_time": "2024-11-23T11:08:21.072905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "src_word_to_index = {w:i for i,w in enumerate(src_vocab)}\n",
    "src_index_to_word = {i:w for i,w in enumerate(src_vocab)}\n",
    "trg_word_to_index = {w:i for i,w in enumerate(trg_vocab)}\n",
    "trg_index_to_word = {i:w for i,w in enumerate(trg_vocab)}\n",
    "'''\n",
    "class Vocab():\n",
    "    def __init__(self):\n",
    "         self.word_to_index = {'<sos>':0,'<eos>':1,'<pad>':2}\n",
    "         self.index_to_word = {0:'<sos>',1:'<eos>',2:'<pad>'}\n",
    "         self.word_count = 3\n",
    "    \n",
    "    def add_word(self,word):\n",
    "        if word not in self.word_to_index:\n",
    "            self.word_to_index[word] = self.word_count\n",
    "            self.index_to_word[self.word_count] = word\n",
    "            self.word_count += 1\n",
    "    \n",
    "    def add_sentence(self,sentence):\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "\n"
   ],
   "id": "3039aa6d6c70f1c0",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:08:21.197876Z",
     "start_time": "2024-11-23T11:08:21.166634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src_vocab = Vocab()\n",
    "for sentence in src_sentences:\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        src_vocab.add_word(word)\n",
    "trg_vocab = Vocab()\n",
    "for sentence in trg_sentences:\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        trg_vocab.add_word(word)\n",
    "len(src_vocab.word_to_index),len(trg_vocab.word_to_index)"
   ],
   "id": "22ceb47ac25d2073",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 120)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:04:38.788897900Z",
     "start_time": "2024-11-23T11:26:17.710382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sentencetoindexes(sentence,vocab):\n",
    "    return [vocab.word_to_index[word] for word in nltk.word_tokenize(sentence)]\n",
    "sentencetoindexes(src_sentences[0],src_vocab)\n",
    "def make_data(src_sentences,trg_sentences,src_vocab,trg_vocab):\n",
    "    src_data = []\n",
    "    trg_data = []\n",
    "    for i,(src_sentence,trg_sentence) in enumerate(zip(src_sentences,trg_sentences)):\n",
    "        src_indexes = sentencetoindexes(src_sentence,src_vocab)\n",
    "        src_indexed = [sos_token] + src_indexes + [eos_token] + [pad_token]*(max_input_len-len(src_indexes))\n",
    "        trg_indexes = sentencetoindexes(trg_sentence,trg_vocab)\n",
    "        trg_indexed = [sos_token] + trg_indexes + [eos_token] + [pad_token]*(max_output_len-len(trg_indexes))\n",
    "        src_data.append(src_indexed)\n",
    "        trg_data.append(trg_indexed)\n",
    "    src_data = torch.LongTensor(src_data)\n",
    "    trg_data = torch.LongTensor(trg_data)\n",
    "    return src_data,trg_data\n",
    "src_data,trg_data = make_data(src_sentences,trg_sentences,src_vocab,trg_vocab)      \n",
    "src_data.shape,trg_data.shape\n",
    "src_batch = DataLoader(src_data,batch_size=batch_size)\n",
    "trg_batch = DataLoader(trg_data,batch_size=batch_size)\n",
    "for data in src_batch:\n",
    "    print(data.shape)\n",
    "    break"
   ],
   "id": "5978510d4ffc6bac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 48])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T17:13:01.476956Z",
     "start_time": "2024-11-23T17:13:01.318380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_dim,embedding_dim,hidden_dim):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim,embedding_dim) \n",
    "        self.rnn = nn.GRU(embedding_dim,hidden_dim,batch_first=True)\n",
    "    \n",
    "    def forward(self,src):\n",
    "        embedding = self.embedding(src)\n",
    "        #print(embedding.shape)\n",
    "        outputs,hidden = self.rnn(embedding)\n",
    "        return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,output_dim,embedding_dim,hidden_dim):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim,embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim,hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim,output_dim)\n",
    "        self.vocab_size = output_dim\n",
    "    \n",
    "    \n",
    "    def forward_cell(self,input,hidden):\n",
    "        input = input.unsqueeze(0) #   (1,batch_size)\n",
    "        embedding = self.embedding(input) # (1,batch_size,embedding_dim)\n",
    "        #print('embedding of decoder 0.shape',embedding.shape)\n",
    "        output,hidden = self.rnn(embedding,hidden)# (1,batch_size,hidden_dim)\n",
    "        prediction = self.fc(output)\n",
    "        #print(\"pred\",prediction.shape,\"hidden\",hidden.shape)\n",
    "        return prediction,hidden\n",
    "    def forward(self,x,hidden,if_teacher_forcing):\n",
    "        #print(\"decoder input shape\",x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        outputs = torch.zeros(seq_len,batch_size,self.vocab_size)\n",
    "        input = x[:,0] # (batch_size)\n",
    "        #print(\"decoder input 0.shape\",input.shape) \n",
    "        for i in range(1,max_output_len):\n",
    "            output,hidden = self.forward_cell(input,hidden) # (batch_size,output_dim)\n",
    "            output = output.squeeze(0)\n",
    "            outputs[i] = output\n",
    "            if(if_teacher_forcing):\n",
    "                input = x[:,i]\n",
    "            else:\n",
    "                input = torch.argmax(output,dim=1) # (batch_size)\n",
    "        return outputs\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,encoder,decoder,if_teacher_forcing):\n",
    "        super(Seq2Seq,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.if_teacher_forcing = if_teacher_forcing\n",
    "        \n",
    "    def forward(self,src,trg):\n",
    "        hidden = self.encoder(src)\n",
    "        #print(\"encoder hiddem:\",hidden.shape)\n",
    "        outputs = self.decoder(trg,hidden,self.if_teacher_forcing)\n",
    "        return outputs.permute(1,2,0)\n",
    "    \n",
    "    def pred(self,src):\n",
    "        hidden = self.encoder(src)\n",
    "        outputs = self.decoder(src,hidden,self.if_teacher_forcing)\n",
    "        outputs = torch.argmax(outputs,dim=2)\n",
    "        print(outputs.shape)\n",
    "        return outputs\n",
    "    \n",
    "model = Seq2Seq(Encoder(len(src_vocab.word_to_index),256,512),Decoder(len(trg_vocab.word_to_index),256,512),True)\n",
    "for src,trg in zip(src_batch,trg_batch):\n",
    "    print(model(src,trg).shape)\n",
    "    break        \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ],
   "id": "7b0e66f2ba4092d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 120, 48])\n"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T17:05:54.723570Z",
     "start_time": "2024-11-23T17:02:10.197047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "epoch = 500\n",
    "for i in range(epoch):\n",
    "    for src,trg in zip(src_batch,trg_batch):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src,trg)\n",
    "        #print(output.shape)\n",
    "        l = loss(output,trg)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        if i%100 == 0:\n",
    "            print(l.item())\n",
    "        \n",
    "    "
   ],
   "id": "f2b0d2392bd1cd44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.851202011108398\n",
      "0.30413660407066345\n",
      "0.3007989823818207\n",
      "0.30006179213523865\n",
      "0.2997521460056305\n"
     ]
    }
   ],
   "execution_count": 166
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predictions",
   "id": "3883c274ba6fa318"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T17:14:51.376824Z",
     "start_time": "2024-11-23T17:14:50.922040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for src,trg in zip(src_batch,trg_batch):\n",
    "    for i in range(5):\n",
    "        print(\"src:\",[src_vocab.index_to_word[word.item()] for word in src[i]])\n",
    "        print(\"trg:\",[trg_vocab.index_to_word[word.item()] for word in trg[i]])\n",
    "        print(\"pred:\",[trg_vocab.index_to_word[word.item()] for word in model.pred(src)[:,i]])\n",
    "    break"
   ],
   "id": "198c3fe445f1aeea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: ['<sos>', 'when', 'working', 'in', 'sweden', ',', 'foreigners', 'have', 'the', 'same', 'rights', 'and', 'obligations', 'as', 'permanent', 'residents', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "trg: ['<sos>', 'tout', 'étranger', 'travaillant', 'en', 'suède', 'est', 'soumis', 'aux', 'mêmes', 'droits', 'et', 'obligations', 'que', 'les', 'résidents', 'permanents', 'en', 'suède', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([48, 10])\n",
      "pred: ['<sos>', 'situation', 'applique', 'leur', 'diffèrent', 'étranger', 'cours', 'toute', 'ce', 'toute', 'toute', 'aux', 'pour', 'pour', 'existence', 'existence', 'diffèrent', 'diffèrent', 'au', 'obligations', 'obligations', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', '<sos>', '<sos>']\n",
      "src: ['<sos>', 'areas', 'covered', 'by', 'posted', 'workers', '’', 'rights', 'are', ':', 'working', 'environment', ',', 'minimum', 'wages', 'and', 'holiday', 'pay', ',', 'regulations', 'on', 'working', 'hours', ',', 'workplace', 'discrimination', 'and', 'parental', 'leave', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "trg: ['<sos>', 'en', 'ce', 'qui', 'concerne', 'les', 'impôts', 'et', 'les', 'avantages', 'sociaux', ',', 'les', 'règlements', 'concernant', 'les', 'travailleurs', 'étrangers', 'diffèrent', 'selon', 'leur', 'situation', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([48, 10])\n",
      "pred: ['<sos>', 'situation', 'signalée', 'cours', 'étranger', 'horaires', 'suède', 'notre', 'aux', 'lieu', 'lieu', 'lieu', 'avantages', 'cours', 's', 'pays', 'verket', 'un', 'personne', 'personne', 'résidents', 'situation', 'leur', 'être', 'suède', 'suède', 'désigner', 'verket', ',', 'contrat', 'ou', 'au', 'obligations', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', '<sos>', '<sos>']\n",
      "src: ['<sos>', 'regarding', 'taxes', 'and', 'social', 'benefits', ',', 'there', 'are', 'different', 'regulations', 'for', 'foreign', 'workers', 'depending', 'on', 'their', 'situation', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "trg: ['<sos>', 'pour', 'en', 'savoir', 'plus', ',', 'consultez', 'le', 'site', 'www.av.se/posting', 'à', 'l', '’', 'office', 'suédois', 'de', 'l', '’', 'environnement', 'du', 'travail', 'arbetsmiljö-', 'verket', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([48, 10])\n",
      "pred: ['<sos>', 'situation', 'l', 'obligations', 'pour', 'personne', 'étranger', 'cours', 'agence', 'la', ',', 'résidents', 'travail', 'nous', 'suède', 'suède', 'situation', 'le', 'employeurs', 'aux', 'au', 'obligations', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', '<sos>', '<sos>']\n",
      "src: ['<sos>', 'more', 'information', 'can', 'be', 'found', 'at', 'www.av.se/posting', 'applies', 'to', 'foreign', 'employers', ',', 'both', 'inside', 'and', 'outside', 'the', 'eu', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "trg: ['<sos>', 'cette', 'obligation', 's', '’', 'applique', 'aux', 'employeurs', 'des', 'pays', 'appartenant', 'ou', 'non', 'à', 'l', '’', 'union', 'européenne', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([48, 10])\n",
      "pred: ['<sos>', 'situation', 'impôts', 'impôts', 'nous', 'existence', 'mission', 'permanents', 'respectée', 'ou', 'contrat', 'nous', 'savoir', 'cours', 'agence', 'employeurs', 'pour', 'faire', 'toute', 'personne', 'aux', 'au', ',', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', '<sos>', '<sos>']\n",
      "src: ['<sos>', 'the', 'employer', 'is', 'also', 'required', 'to', 'appoint', 'a', 'contact', 'person', 'in', 'sweden', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "trg: ['<sos>', 'l', '’', 'employeur', 'est', 'également', 'tenu', 'de', 'désigner', 'une', 'personne', 'de', 'contact', 'en', 'suède', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([48, 10])\n",
      "pred: ['<sos>', 'situation', 'situation', 'diffèrent', 'un', 'existence', 'arbetsmiljö-', 'arbetsmiljö-', 'arbetsmiljö-', 'outre', 'existence', 'permanents', 'diffèrent', 'appartenant', ',', 'au', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', '<sos>', '<sos>']\n"
     ]
    }
   ],
   "execution_count": 179
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
